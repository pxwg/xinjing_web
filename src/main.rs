use axum::{
    extract::ws::{Message, WebSocket, WebSocketUpgrade},
    response::IntoResponse,
    routing::get,
    Router,
};
use futures::{sink::SinkExt, stream::StreamExt};
use opus::{Channels, Decoder};
use serde::{Deserialize, Serialize};
use std::net::SocketAddr;
use std::sync::Arc;
use tracing::{error, info, warn};
use whisper_rs::{FullParams, SamplingStrategy, WhisperContext, WhisperContextParameters};

// --- åè®®å®šä¹‰ ---
#[derive(Debug, Deserialize)]
#[serde(tag = "type", rename_all = "snake_case")]
enum DeviceMessage {
    Hello { version: String },
    Event { key: String, value: String },
}

#[derive(Debug, Serialize)]
struct ServerResponse {
    #[serde(rename = "type")]
    msg_type: String,
    emotion: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    text: Option<String>,
}

#[tokio::main]
async fn main() {
    // 1. åˆå§‹åŒ–æ—¥å¿—
    tracing_subscriber::fmt()
        .with_max_level(tracing::Level::INFO)
        .init();

    // 2. åŠ è½½ Whisper ä¸­æ–‡æ¨¡å‹
    let model_path = "ggml-base.bin";
    if !std::path::Path::new(model_path).exists() {
        panic!(
            "âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹ '{}'ã€‚è¯·å…ˆä¸‹è½½æ”¯æŒä¸­æ–‡çš„ ggml æ¨¡å‹ (é .en ç‰ˆ)ã€‚",
            model_path
        );
    }

    info!("æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹ (è¿™ä¹Ÿæ˜¯å¤§è„‘å¯åŠ¨æœ€æ…¢çš„ä¸€æ­¥)...");
    let ctx = Arc::new(
        WhisperContext::new_with_params(model_path, WhisperContextParameters::default())
            .expect("æ¨¡å‹åŠ è½½å¤±è´¥"),
    );
    info!("âœ… Whisper æ¨¡å‹åŠ è½½å®Œæ¯•ï¼Œæ”¯æŒä¸­æ–‡è¯†åˆ«");

    // 3. å¯åŠ¨æœåŠ¡
    let app = Router::new().route("/ws", get(move |ws| ws_handler(ws, ctx.clone())));
    let addr = SocketAddr::from(([0, 0, 0, 0], 4321));
    info!("ğŸš€ å¿ƒé•œ (Heart Mirror) å¤§è„‘å·²å¯åŠ¨ï¼Œç›‘å¬: {}", addr);

    let listener = tokio::net::TcpListener::bind(&addr).await.unwrap();
    axum::serve(listener, app).await.unwrap();
}

async fn ws_handler(ws: WebSocketUpgrade, ctx: Arc<WhisperContext>) -> impl IntoResponse {
    ws.on_upgrade(move |socket| handle_socket(socket, ctx))
}

// --- æ ¸å¿ƒå¤„ç†é€»è¾‘ ---
async fn handle_socket(mut socket: WebSocket, ctx: Arc<WhisperContext>) {
    info!("ğŸ”Œ æ–°çš„è¾¹ç¼˜æ¢é’ˆ (Client) å·²è¿æ¥");

    let mut decoder = match Decoder::new(16000, Channels::Mono) {
        Ok(d) => d,
        Err(e) => {
            error!("Opus Init Error: {}", e);
            return;
        }
    };

    let mut pcm_i16 = [0i16; 5760];
    let mut audio_buffer: Vec<f32> = Vec::with_capacity(16000 * 10);

    // --- VAD å‚æ•° ---
    let mut silence_frames = 0;
    let mut is_recording_speech = false;
    let mut max_recorded_energy: f32 = 0.0;

    const VAD_THRESHOLD_START: f32 = 800.0;
    const VAD_THRESHOLD_END: f32 = 500.0;
    const MAX_SILENCE_FRAMES: usize = 12;

    // B. å‘é€åˆå§‹çŠ¶æ€
    let initial_state = ServerResponse {
        msg_type: "llm".to_string(),
        emotion: "calm".to_string(),
        text: Some("Connected & Ready".to_string()),
    };
    if let Ok(json) = serde_json::to_string(&initial_state) {
        let _ = socket.send(Message::Text(json)).await;
    }

    // C. ä¸»æ¶ˆæ¯å¾ªç¯
    while let Some(msg) = socket.recv().await {
        match msg {
            Ok(Message::Text(text)) => {
                info!("æ”¶åˆ°æ–‡æœ¬å¸§: {}", text);
                if text.contains("ping") {
                    let _ = socket.send(Message::Text("pong".to_string())).await;
                }
                handle_text_frame(&text);
            }

            Ok(Message::Binary(data)) => {
                match decoder.decode(&data, &mut pcm_i16, false) {
                    Ok(samples_count) => {
                        let slice = &pcm_i16[..samples_count];
                        let energy = calculate_rms(slice);

                        // VAD çŠ¶æ€æœº
                        if !is_recording_speech {
                            if energy > VAD_THRESHOLD_START {
                                info!("ğŸ¤ å¼€å§‹å½•éŸ³ (Start Energy: {:.0})", energy);
                                is_recording_speech = true;
                                silence_frames = 0;
                                max_recorded_energy = energy;
                                for &sample in slice {
                                    audio_buffer.push(sample as f32 / 32768.0);
                                }
                            }
                        } else {
                            for &sample in slice {
                                audio_buffer.push(sample as f32 / 32768.0);
                            }

                            if energy > max_recorded_energy {
                                max_recorded_energy = energy;
                            }

                            if energy < VAD_THRESHOLD_END {
                                silence_frames += 1;
                            } else {
                                silence_frames = 0;
                            }

                            // è§¦å‘è¯†åˆ«
                            if silence_frames >= MAX_SILENCE_FRAMES {
                                if audio_buffer.len() > 8000 {
                                    info!(
                                        "â¹ï¸ è¯­éŸ³ç»“æŸï¼Œå³°å€¼èƒ½é‡: {:.0}ï¼Œæäº¤è¯†åˆ«...",
                                        max_recorded_energy
                                    );

                                    let text = run_whisper_inference(&ctx, &audio_buffer);
                                    // 1. åœ¨è¿™é‡Œè½¬ä¸ºç®€ä½“ï¼Œæˆ–è€…ä¾èµ– Prompt çš„æ•ˆæœ
                                    let clean_text = text.trim();

                                    // 2. å¹»è§‰è¿‡æ»¤
                                    if !clean_text.is_empty() && clean_text != "ä½ å»æ‰¾æˆ‘å§" {
                                        // 3. æƒ…ç»ªåˆ†æ (ç°åœ¨èƒ½æ›´å¥½åœ°åŒ¹é…ç®€ä½“å…³é”®è¯äº†)
                                        let emotion =
                                            analyze_emotion(clean_text, max_recorded_energy);

                                        info!("ğŸ—£ï¸ ç»“æœ: [{}] | æƒ…ç»ª: [{}]", clean_text, emotion);

                                        let resp = ServerResponse {
                                            msg_type: "llm".to_string(),
                                            emotion: emotion,
                                            text: Some(clean_text.to_string()),
                                        };
                                        let _ = socket
                                            .send(Message::Text(
                                                serde_json::to_string(&resp).unwrap(),
                                            ))
                                            .await;
                                    } else {
                                        info!("(å¿½ç•¥å¹»è§‰)");
                                    }
                                } else {
                                    info!("(éŸ³é¢‘å¤ªçŸ­ä¸¢å¼ƒ)");
                                }

                                audio_buffer.clear();
                                silence_frames = 0;
                                is_recording_speech = false;
                                max_recorded_energy = 0.0;
                            }
                        }

                        // ä¿æŠ¤æœºåˆ¶
                        if audio_buffer.len() > 16000 * 30 {
                            warn!("ç¼“å†²åŒºè¿‡å¤§ï¼Œé‡ç½®");
                            audio_buffer.clear();
                            is_recording_speech = false;
                        }
                    }
                    Err(e) => warn!("Opus Error: {}", e),
                }
            }
            Ok(Message::Close(_)) => break,
            _ => {}
        }
    }
    info!("è¿æ¥æ–­å¼€");
}

fn handle_text_frame(text: &str) {
    match serde_json::from_str::<DeviceMessage>(text) {
        Ok(DeviceMessage::Hello { version }) => info!("APPæ¡æ‰‹: {}", version),
        Ok(DeviceMessage::Event { key, value }) => info!("APPäº‹ä»¶: {} -> {}", key, value),
        Err(_) => info!("Raw Text: {}", text),
    }
}

fn calculate_rms(samples: &[i16]) -> f32 {
    if samples.is_empty() {
        return 0.0;
    }
    let sum: f32 = samples.iter().map(|&s| (s as f32).powi(2)).sum();
    (sum / samples.len() as f32).sqrt()
}

// --- ç®€å•çš„ç»¼åˆæƒ…ç»ªåˆ†æå™¨ ---
fn analyze_emotion(text: &str, max_energy: f32) -> String {
    let t = text.to_lowercase();

    // 1. æé«˜èƒ½é‡å…œåº• (å¤§å–Šå¤§å«)
    if max_energy > 15000.0 {
        if t.contains("æ»š") || t.contains("æ­»") {
            return "anger".to_string();
        }
        return "fear".to_string();
    }

    // 2. å…³é”®è¯åŒ¹é… (åŸºäºç®€ä½“ä¸­æ–‡)
    if t.contains("å¼€å¿ƒ") || t.contains("å¿«ä¹") || t.contains("å“ˆå“ˆ") || t.contains("æ£’") {
        return "joy".to_string();
    }
    if t.contains("æ»š") || t.contains("çƒ¦") || t.contains("è®¨åŒ") || t.contains("æ°”") {
        return "anger".to_string();
    }
    if t.contains("éš¾è¿‡") || t.contains("ç´¯") || t.contains("è‹¦") || t.contains("å¤±æœ›") {
        return "sadness".to_string();
    }
    if t.contains("æ€•") || t.contains("å“") || t.contains("æ•‘å‘½") {
        return "fear".to_string();
    }
    if t.contains("å®‰") || t.contains("é™") || t.contains("ç¡") {
        return "sleep".to_string();
    }

    // 3. æä½èƒ½é‡å…œåº•
    if max_energy < 1500.0 {
        return "calm".to_string();
    }

    "neutral".to_string()
}

// Whisper æ¨ç†å‡½æ•°
fn run_whisper_inference(ctx: &WhisperContext, data: &[f32]) -> String {
    let mut state = ctx.create_state().expect("æ— æ³•åˆ›å»º Whisper State");
    let mut params = FullParams::new(SamplingStrategy::Greedy { best_of: 1 });

    params.set_language(Some("zh"));

    // ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨ Prompt å¼ºåˆ¶æ¨¡å‹â€œæ¨¡ä»¿â€ç®€ä½“ä¸­æ–‡é£æ ¼
    params.set_initial_prompt("ç®€ä½“ä¸­æ–‡");

    params.set_n_threads(4);
    params.set_print_special(false);
    params.set_print_progress(false);

    if let Err(e) = state.full(params, data) {
        error!("Whisper Fail: {}", e);
        return String::new();
    }

    let num_segments = state.full_n_segments();
    let mut result = String::new();
    for i in 0..num_segments {
        if let Some(segment) = state.get_segment(i) {
            result.push_str(&segment.to_string());
        }
    }
    result
}
