use axum::{
    extract::ws::{Message, WebSocket, WebSocketUpgrade},
    response::IntoResponse,
    routing::get,
    Router,
};
use futures::{sink::SinkExt, stream::StreamExt};
use opus::{Channels, Decoder};
use serde::{Deserialize, Serialize};
use std::net::SocketAddr;
use std::sync::Arc;
use tracing::{error, info, warn};
use whisper_rs::{FullParams, SamplingStrategy, WhisperContext, WhisperContextParameters};

// --- åè®®å®šä¹‰ ---
#[derive(Debug, Deserialize)]
#[serde(tag = "type", rename_all = "snake_case")]
enum DeviceMessage {
    Hello { version: String },
    Event { key: String, value: String },
}

#[derive(Debug, Serialize)]
struct ServerResponse {
    #[serde(rename = "type")]
    msg_type: String,
    emotion: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    text: Option<String>,
}

// --- Ollama API å®šä¹‰ ---
#[derive(Debug, Serialize)]
struct OllamaRequest {
    model: String,
    prompt: String,
    stream: bool,
}

#[derive(Debug, Deserialize)]
struct OllamaResponse {
    response: String,
}

#[tokio::main]
async fn main() {
    // 1. åˆå§‹åŒ–æ—¥å¿—
    tracing_subscriber::fmt()
        .with_max_level(tracing::Level::INFO)
        .init();

    // 2. åŠ è½½ Whisper ä¸­æ–‡æ¨¡å‹
    let model_path = "ggml-base.bin";
    if !std::path::Path::new(model_path).exists() {
        panic!(
            "âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹ '{}'ã€‚è¯·å…ˆä¸‹è½½æ”¯æŒä¸­æ–‡çš„ ggml æ¨¡å‹ (é .en ç‰ˆ)ã€‚",
            model_path
        );
    }

    info!("æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹ (è¿™ä¹Ÿæ˜¯å¤§è„‘å¯åŠ¨æœ€æ…¢çš„ä¸€æ­¥)...");
    let ctx = Arc::new(
        WhisperContext::new_with_params(model_path, WhisperContextParameters::default())
            .expect("æ¨¡å‹åŠ è½½å¤±è´¥"),
    );
    info!("âœ… Whisper æ¨¡å‹åŠ è½½å®Œæ¯•ï¼Œæ”¯æŒä¸­æ–‡è¯†åˆ«");

    // 3. æµ‹è¯• Ollama è¿æ¥
    match test_ollama_connection().await {
        Ok(_) => info!("âœ… Ollama qwen2.5:0.5b æ¨¡å‹è¿æ¥æˆåŠŸ"),
        Err(e) => {
            error!(
                "âŒ Ollama è¿æ¥å¤±è´¥: {}. è¯·ç¡®ä¿ Ollama å·²å¯åŠ¨å¹¶å®‰è£…äº† qwen2.5:0.5b æ¨¡å‹",
                e
            );
            error!("ğŸ’¡ æç¤º: è¿è¡Œ 'ollama run qwen2.5:0.5b' æ¥å®‰è£…æ¨¡å‹");
        }
    }

    // 4. å¯åŠ¨æœåŠ¡
    let app = Router::new().route("/ws", get(move |ws| ws_handler(ws, ctx.clone())));
    let addr = SocketAddr::from(([0, 0, 0, 0], 4321));
    info!("ğŸš€ å¿ƒé•œ (Heart Mirror) å¤§è„‘å·²å¯åŠ¨ï¼Œç›‘å¬: {}", addr);

    let listener = tokio::net::TcpListener::bind(&addr).await.unwrap();
    axum::serve(listener, app).await.unwrap();
}

async fn test_ollama_connection() -> Result<(), Box<dyn std::error::Error>> {
    let client = reqwest::Client::new();
    let test_prompt = "æµ‹è¯•";

    let request = OllamaRequest {
        model: "qwen2.5:0.5b".to_string(),
        prompt: test_prompt.to_string(),
        stream: false,
    };

    let response = client
        .post("http://127.0.0.1:11434/api/generate")
        .json(&request)
        .timeout(std::time::Duration::from_secs(10))
        .send()
        .await?;

    if response.status().is_success() {
        Ok(())
    } else {
        Err(format!("Ollama è¿”å›é”™è¯¯çŠ¶æ€: {}", response.status()).into())
    }
}

async fn ws_handler(ws: WebSocketUpgrade, ctx: Arc<WhisperContext>) -> impl IntoResponse {
    ws.on_upgrade(move |socket| handle_socket(socket, ctx))
}

// --- æ ¸å¿ƒå¤„ç†é€»è¾‘ ---
async fn handle_socket(mut socket: WebSocket, ctx: Arc<WhisperContext>) {
    info!("ğŸ”Œ æ–°çš„è¾¹ç¼˜æ¢é’ˆ (Client) å·²è¿æ¥");

    let mut decoder = match Decoder::new(16000, Channels::Mono) {
        Ok(d) => d,
        Err(e) => {
            error!("Opus Init Error: {}", e);
            return;
        }
    };

    let mut pcm_i16 = [0i16; 5760];
    let mut audio_buffer: Vec<f32> = Vec::with_capacity(16000 * 10);

    // --- VAD å‚æ•° ---
    let mut silence_frames = 0;
    let mut is_recording_speech = false;
    let mut max_recorded_energy: f32 = 0.0;

    const VAD_THRESHOLD_START: f32 = 800.0;
    const VAD_THRESHOLD_END: f32 = 500.0;
    const MAX_SILENCE_FRAMES: usize = 12;

    // B. å‘é€åˆå§‹çŠ¶æ€
    let initial_state = ServerResponse {
        msg_type: "llm".to_string(),
        emotion: "calm".to_string(),
        text: Some("Connected & Ready".to_string()),
    };
    if let Ok(json) = serde_json::to_string(&initial_state) {
        let _ = socket.send(Message::Text(json)).await;
    }

    // C. ä¸»æ¶ˆæ¯å¾ªç¯
    while let Some(msg) = socket.recv().await {
        match msg {
            Ok(Message::Text(text)) => {
                info!("æ”¶åˆ°æ–‡æœ¬å¸§: {}", text);
                if text.contains("ping") {
                    let _ = socket.send(Message::Text("pong".to_string())).await;
                }
                handle_text_frame(&text);
            }

            Ok(Message::Binary(data)) => {
                match decoder.decode(&data, &mut pcm_i16, false) {
                    Ok(samples_count) => {
                        let slice = &pcm_i16[..samples_count];
                        let energy = calculate_rms(slice);

                        // VAD çŠ¶æ€æœº
                        if !is_recording_speech {
                            if energy > VAD_THRESHOLD_START {
                                info!("ğŸ¤ å¼€å§‹å½•éŸ³ (Start Energy: {:.0})", energy);
                                is_recording_speech = true;
                                silence_frames = 0;
                                max_recorded_energy = energy;
                                for &sample in slice {
                                    audio_buffer.push(sample as f32 / 32768.0);
                                }
                            }
                        } else {
                            for &sample in slice {
                                audio_buffer.push(sample as f32 / 32768.0);
                            }

                            if energy > max_recorded_energy {
                                max_recorded_energy = energy;
                            }

                            if energy < VAD_THRESHOLD_END {
                                silence_frames += 1;
                            } else {
                                silence_frames = 0;
                            }

                            // è§¦å‘è¯†åˆ«
                            if silence_frames >= MAX_SILENCE_FRAMES {
                                if audio_buffer.len() > 8000 {
                                    info!(
                                        "â¹ï¸ è¯­éŸ³ç»“æŸï¼Œå³°å€¼èƒ½é‡: {:.0}ï¼Œæäº¤è¯†åˆ«...",
                                        max_recorded_energy
                                    );

                                    let text = run_whisper_inference(&ctx, &audio_buffer);
                                    let clean_text = text.trim();

                                    // å¹»è§‰è¿‡æ»¤
                                    if !clean_text.is_empty() && clean_text != "ä½ å»æ‰¾æˆ‘å§" {
                                        // ä½¿ç”¨ Ollama è¿›è¡Œæƒ…ç»ªåˆ†æ
                                        let emotion = analyze_emotion_with_llm(clean_text).await;

                                        info!("ğŸ—£ï¸ ç»“æœ: [{}] | æƒ…ç»ª: [{}]", clean_text, emotion);

                                        let resp = ServerResponse {
                                            msg_type: "llm".to_string(),
                                            emotion: emotion,
                                            text: Some(clean_text.to_string()),
                                        };
                                        let _ = socket
                                            .send(Message::Text(
                                                serde_json::to_string(&resp).unwrap(),
                                            ))
                                            .await;
                                    } else {
                                        info!("(å¿½ç•¥å¹»è§‰)");
                                    }
                                } else {
                                    info!("(éŸ³é¢‘å¤ªçŸ­ä¸¢å¼ƒ)");
                                }

                                audio_buffer.clear();
                                silence_frames = 0;
                                is_recording_speech = false;
                                max_recorded_energy = 0.0;
                            }
                        }

                        // ä¿æŠ¤æœºåˆ¶
                        if audio_buffer.len() > 16000 * 30 {
                            warn!("ç¼“å†²åŒºè¿‡å¤§ï¼Œé‡ç½®");
                            audio_buffer.clear();
                            is_recording_speech = false;
                        }
                    }
                    Err(e) => warn!("Opus Error: {}", e),
                }
            }
            Ok(Message::Close(_)) => break,
            _ => {}
        }
    }
    info!("è¿æ¥æ–­å¼€");
}

fn handle_text_frame(text: &str) {
    match serde_json::from_str::<DeviceMessage>(text) {
        Ok(DeviceMessage::Hello { version }) => info!("APPæ¡æ‰‹: {}", version),
        Ok(DeviceMessage::Event { key, value }) => info!("APPäº‹ä»¶: {} -> {}", key, value),
        Err(_) => info!("Raw Text: {}", text),
    }
}

fn calculate_rms(samples: &[i16]) -> f32 {
    if samples.is_empty() {
        return 0.0;
    }
    let sum: f32 = samples.iter().map(|&s| (s as f32).powi(2)).sum();
    (sum / samples.len() as f32).sqrt()
}

// --- ä½¿ç”¨ Ollama Qwen2.5:0.5b è¿›è¡Œæƒ…ç»ªåˆ†æ ---
async fn analyze_emotion_with_llm(text: &str) -> String {
    let client = reqwest::Client::new();

    let prompt = format!(
    "Analyze the sentiment of the following text. ONLY output ONE word, strictly from this list: [[joy, anger, sadness, fear, calm, neutral, sleep]]. Do NOT output anything else.\n\nText: {}\n\nSentiment:",
    text
    );

    let request = OllamaRequest {
        model: "qwen2.5:1.5b".to_string(),
        prompt,
        stream: false,
    };

    match client
        .post("http://127.0.0.1:11434/api/generate")
        .json(&request)
        .timeout(std::time::Duration::from_secs(5))
        .send()
        .await
    {
        Ok(response) => {
            if let Ok(ollama_resp) = response.json::<OllamaResponse>().await {
                let emotion = ollama_resp.response.trim().to_lowercase();

                // éªŒè¯è¿”å›çš„æƒ…ç»ªæ˜¯å¦åœ¨å…è®¸çš„åˆ—è¡¨ä¸­
                let valid_emotions = [
                    "joy", "anger", "sadness", "fear", "calm", "neutral", "sleep",
                ];
                for valid_emotion in valid_emotions.iter() {
                    if emotion.contains(valid_emotion) {
                        return valid_emotion.to_string();
                    }
                }

                info!("LLM è¿”å›äº†éé¢„æœŸçš„æƒ…ç»ª: {}, ä½¿ç”¨ neutral", emotion);
                "neutral".to_string()
            } else {
                warn!("è§£æ Ollama å“åº”å¤±è´¥ï¼Œä½¿ç”¨ neutral");
                "neutral".to_string()
            }
        }
        Err(e) => {
            warn!("Ollama è¯·æ±‚å¤±è´¥: {}, ä½¿ç”¨ neutral", e);
            "neutral".to_string()
        }
    }
}

// Whisper æ¨ç†å‡½æ•°
fn run_whisper_inference(ctx: &WhisperContext, data: &[f32]) -> String {
    let mut state = ctx.create_state().expect("æ— æ³•åˆ›å»º Whisper State");
    let mut params = FullParams::new(SamplingStrategy::Greedy { best_of: 1 });

    params.set_language(Some("zh"));
    params.set_initial_prompt("ç®€ä½“ä¸­æ–‡");
    params.set_n_threads(4);
    params.set_print_special(false);
    params.set_print_progress(false);

    if let Err(e) = state.full(params, data) {
        error!("Whisper Fail: {}", e);
        return String::new();
    }

    let num_segments = state.full_n_segments();
    let mut result = String::new();
    for i in 0..num_segments {
        if let Some(segment) = state.get_segment(i) {
            result.push_str(&segment.to_string());
        }
    }
    result
}
